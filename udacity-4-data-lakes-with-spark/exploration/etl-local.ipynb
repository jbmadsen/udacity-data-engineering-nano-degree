{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets try to run the ETL process locally, step by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "import os\n",
    "import sys\n",
    "import configparser\n",
    "import boto3\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pyspark.sql as Spark\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a spark session, or retrieve a matching one if it exists\n",
    "spark = Spark.SparkSession \\\n",
    "    .builder \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = \"./data/\"\n",
    "output_data = \"./output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute unpack-local.sh \n",
    "# This unpacks the zip files in ./data/ and move to dirs matching S3 for the \"real\" etl.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First up, songs data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read song data file\n",
    "song_data = input_data + \"song_data/*/*/*/*.json\"\n",
    "# Documentation: https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrameReader\n",
    "# columnNameOfCorruptRecord: allows renaming the new field having malformed string created by PERMISSIVE mode.\n",
    "# (DEFAULT) PERMISSIVE: To keep corrupt records, an user can set a string type field named columnNameOfCorruptRecord in an user-defined schema\n",
    "df = spark.read.json(song_data, columnNameOfCorruptRecord='corrupt_record').drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract columns to create songs table\n",
    "# Udacity instructions: \n",
    "# songs - songs in music database\n",
    "# song_id, title, artist_id, year, duration\n",
    "songs_table = df.select(\"song_id\",\"title\",\"artist_id\",\"year\",\"duration\").drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write songs table to parquet files partitioned by year and artist\n",
    "songs_table.write.parquet(output_data + \"songs/\", \n",
    "                          mode=\"overwrite\",\n",
    "                          partitionBy=[\"year\",\"artist_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract columns to create artists table\n",
    "# Udacity instructions: \n",
    "# artists - artists in music database\n",
    "# artist_id, name, location, lattitude, longitude\n",
    "artists_table = df.select(\"artist_id\",\"artist_name\",\"artist_location\",\"artist_latitude\",\"artist_longitude\").drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write artists table to parquet files\n",
    "artists_table.write.parquet(output_data + \"artists/\", \n",
    "                            mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python37664bit079b8e0c18c84c07a446e24cf94e2db0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}