{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Lets try to run the ETL process locally, step by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Import\n",
    "import os\n",
    "import sys\n",
    "import configparser\n",
    "import boto3\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pyspark.sql as Spark\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Creates a spark session, or retrieve a matching one if it exists\n",
    "spark = Spark.SparkSession \\\n",
    "    .builder \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "input_data = \"./data/\"\n",
    "output_data = \"./output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# First up, songs data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# read song data file\n",
    "song_data = input_data + \"song_data/*/*/*/*.json\"\n",
    "# Documentation: https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrameReader\n",
    "# columnNameOfCorruptRecord: allows renaming the new field having malformed string created by PERMISSIVE mode.\n",
    "# (DEFAULT) PERMISSIVE: To keep corrupt records, an user can set a string type field named columnNameOfCorruptRecord in an user-defined schema\n",
    "df = spark.read.json(song_data, columnNameOfCorruptRecord='corrupt_record').drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------------+--------------------+----------------+--------------------+---------+---------+------------------+--------------------+----+\n",
      "|         artist_id|artist_latitude|     artist_location|artist_longitude|         artist_name| duration|num_songs|           song_id|               title|year|\n",
      "+------------------+---------------+--------------------+----------------+--------------------+---------+---------+------------------+--------------------+----+\n",
      "|ARPFHN61187FB575F6|       41.88415|         Chicago, IL|       -87.63241|         Lupe Fiasco|279.97995|        1|SOWQTQZ12A58A7B63E|Streets On Fire (...|   0|\n",
      "|AR1Y2PT1187FB5B9CE|       27.94017|             Brandon|       -82.32547|         John Wesley|484.62322|        1|SOLLHMX12AB01846DC|   The Emperor Falls|   0|\n",
      "|AR7G5I41187FB4CE6C|           null|     London, England|            null|            Adam Ant|233.40363|        1|SONHOTT12A8C13493C|     Something Girls|1982|\n",
      "|AR10USD1187B99F3F1|           null|Burlington, Ontar...|            null|Tweeterfriendly M...|189.57016|        1|SOHKNRJ12A6701D1F8|        Drop of Rain|   0|\n",
      "|ARD7TVE1187B99BFB1|           null|     California - LA|            null|              Casual|218.93179|        1|SOMZWCG12A8C13C480|    I Didn't Mean To|   0|\n",
      "+------------------+---------------+--------------------+----------------+--------------------+---------+---------+------------------+--------------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lets display\n",
    "df.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# extract columns to create songs table\n",
    "# Udacity instructions: \n",
    "# songs - songs in music database\n",
    "# song_id, title, artist_id, year, duration\n",
    "songs_table = df.select(df.song_id,\n",
    "                        df.title,\n",
    "                        df.artist_id,\n",
    "                        df.year,\n",
    "                        df.duration).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+------------------+----+---------+\n",
      "|           song_id|               title|         artist_id|year| duration|\n",
      "+------------------+--------------------+------------------+----+---------+\n",
      "|SOGOSOV12AF72A285E|   ¿Dónde va Chichi?|ARGUVEV1187B98BA17|1997|313.12934|\n",
      "|SOTTDKS12AB018D69B|It Wont Be Christmas|ARMBR4Y1187B9990EB|   0|241.47546|\n",
      "|SOBBUGU12A8C13E95D|Setting Fire to S...|ARMAC4T1187FB3FA4C|2004|207.77751|\n",
      "|SOIAZJW12AB01853F1|          Pink World|AR8ZCNI1187B9A069B|1984|269.81832|\n",
      "|SONYPOM12A8C13B2D7|I Think My Wife I...|ARDNS031187B9924F0|2005|186.48771|\n",
      "+------------------+--------------------+------------------+----+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lets display\n",
    "songs_table.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# write songs table to parquet files partitioned by year and artist\n",
    "songs_table.write.parquet(output_data + \"songs/\", \n",
    "                          mode=\"overwrite\",\n",
    "                          partitionBy=[\"year\",\"artist_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# extract columns to create artists table\n",
    "# Udacity instructions: \n",
    "# artists - artists in music database\n",
    "# artist_id, name, location, lattitude, longitude\n",
    "artists_table = df.select(df.artist_id,\n",
    "                          df.artist_name.alias(\"name\"),\n",
    "                          df.artist_location.alias(\"location\"),\n",
    "                          df.artist_latitude.alias(\"latitude\"),\n",
    "                          df.artist_longitude.alias(\"longitude\")).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------------+---------------+--------+----------+\n",
      "|         artist_id|           name|       location|latitude| longitude|\n",
      "+------------------+---------------+---------------+--------+----------+\n",
      "|ARPBNLO1187FB3D52F|       Tiny Tim|   New York, NY|40.71455| -74.00712|\n",
      "|ARXR32B1187FB57099|            Gob|               |    null|      null|\n",
      "|AROGWRA122988FEE45|Christos Dantis|               |    null|      null|\n",
      "|AREVWGE1187B9B890A|     Bitter End|      Noci (BA)| -13.442|  -41.9952|\n",
      "|ARBGXIG122988F409D|     Steel Rain|California - SF|37.77916|-122.42005|\n",
      "+------------------+---------------+---------------+--------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lets display\n",
    "artists_table.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# write artists table to parquet files\n",
    "artists_table.write.parquet(output_data + \"artists/\", \n",
    "                            mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Next up, log data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# get filepath to log data file\n",
    "log_data = input_data + \"log_data/*/*/*.json\"\n",
    "# read log data file\n",
    "df = spark.read.json(log_data, \n",
    "                     columnNameOfCorruptRecord='corrupt_record').drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+---------+------+-------------+--------+---------+-----+--------------------+------+--------+-----------------+---------+--------------------+------+-------------+--------------------+------+\n",
      "|       artist|     auth|firstName|gender|itemInSession|lastName|   length|level|            location|method|    page|     registration|sessionId|                song|status|           ts|           userAgent|userId|\n",
      "+-------------+---------+---------+------+-------------+--------+---------+-----+--------------------+------+--------+-----------------+---------+--------------------+------+-------------+--------------------+------+\n",
      "|      Fat Joe|Logged In|     Kate|     F|           21| Harrell|241.34485| paid|Lansing-East Lans...|   PUT|NextSong|1.540472624796E12|      605|Safe 2 Say [The I...|   200|1542296032796|\"Mozilla/5.0 (X11...|    97|\n",
      "|  Linkin Park|Logged In|     Kate|     F|           33| Harrell|259.86567| paid|Lansing-East Lans...|   PUT|NextSong|1.540472624796E12|      605|         My December|   200|1542299023796|\"Mozilla/5.0 (X11...|    97|\n",
      "|The Saturdays|Logged In|    Chloe|     F|           20|  Cuevas|176.95302| paid|San Francisco-Oak...|   PUT|NextSong|1.540940782796E12|      630|     If This Is Love|   200|1542318319796|Mozilla/5.0 (Wind...|    49|\n",
      "|  Wim Mertens|Logged In|   Aleena|     F|           71|   Kirby|240.79628| paid|Waterloo-Cedar Fa...|   PUT|NextSong|1.541022995796E12|      619|          Naviamente|   200|1542321121796|Mozilla/5.0 (Maci...|    44|\n",
      "|         null|Logged In|    Tegan|     F|           26|  Levine|     null| paid|Portland-South Po...|   GET|    Home|1.540794356796E12|      774|                null|   200|1542768175796|\"Mozilla/5.0 (Mac...|    80|\n",
      "+-------------+---------+---------+------+-------------+--------+---------+-----+--------------------+------+--------+-----------------+---------+--------------------+------+-------------+--------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lets display\n",
    "df.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# filter by actions for song plays\n",
    "df = df.filter(df.page == \"NextSong\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# extract columns for users table\n",
    "# Udacity instructions:\n",
    "# users - users in the app\n",
    "# user_id, first_name, last_name, gender, level\n",
    "users_table = df.select(df.userId.alias(\"user_id\"),\n",
    "                        df.firstName.alias(\"first_name\"),\n",
    "                        df.lastName.alias(\"last_name\"),\n",
    "                        df.gender,\n",
    "                        df.level).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+---------+------+-----+\n",
      "|user_id|first_name|last_name|gender|level|\n",
      "+-------+----------+---------+------+-----+\n",
      "|     26|      Ryan|    Smith|     M| free|\n",
      "|      7|    Adelyn|   Jordan|     F| free|\n",
      "|     71|    Ayleen|     Wise|     F| free|\n",
      "|     81|    Sienna|    Colon|     F| free|\n",
      "|     87|    Dustin|      Lee|     M| free|\n",
      "+-------+----------+---------+------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lets display\n",
    "users_table.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# write users table to parquet files\n",
    "users_table.write.parquet(output_data + \"users/\", \n",
    "                          mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create timestamp column from original timestamp column\n",
    "get_timestamp = F.udf(lambda x : datetime.utcfromtimestamp(int(x)/1000), T.TimestampType())\n",
    "df = df.withColumn(\"start_time\", get_timestamp('ts'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------+---------+------+-------------+---------+---------+-----+--------------------+------+--------+-----------------+---------+--------------------+------+-------------+--------------------+------+--------------------+\n",
      "|            artist|     auth|firstName|gender|itemInSession| lastName|   length|level|            location|method|    page|     registration|sessionId|                song|status|           ts|           userAgent|userId|          start_time|\n",
      "+------------------+---------+---------+------+-------------+---------+---------+-----+--------------------+------+--------+-----------------+---------+--------------------+------+-------------+--------------------+------+--------------------+\n",
      "|           Fat Joe|Logged In|     Kate|     F|           21|  Harrell|241.34485| paid|Lansing-East Lans...|   PUT|NextSong|1.540472624796E12|      605|Safe 2 Say [The I...|   200|1542296032796|\"Mozilla/5.0 (X11...|    97|2018-11-15 15:33:...|\n",
      "|       Linkin Park|Logged In|     Kate|     F|           33|  Harrell|259.86567| paid|Lansing-East Lans...|   PUT|NextSong|1.540472624796E12|      605|         My December|   200|1542299023796|\"Mozilla/5.0 (X11...|    97|2018-11-15 16:23:...|\n",
      "|     The Saturdays|Logged In|    Chloe|     F|           20|   Cuevas|176.95302| paid|San Francisco-Oak...|   PUT|NextSong|1.540940782796E12|      630|     If This Is Love|   200|1542318319796|Mozilla/5.0 (Wind...|    49|2018-11-15 21:45:...|\n",
      "|       Wim Mertens|Logged In|   Aleena|     F|           71|    Kirby|240.79628| paid|Waterloo-Cedar Fa...|   PUT|NextSong|1.541022995796E12|      619|          Naviamente|   200|1542321121796|Mozilla/5.0 (Maci...|    44|2018-11-15 22:32:...|\n",
      "|The Avett Brothers|Logged In| Mohammad|     M|            1|Rodriguez| 271.0722| paid|Sacramento--Rosev...|   PUT|NextSong|1.540511766796E12|      744|   The Perfect Space|   200|1542786093796|\"Mozilla/5.0 (Mac...|    88|2018-11-21 07:41:...|\n",
      "+------------------+---------+---------+------+-------------+---------+---------+-----+--------------------+------+--------+-----------------+---------+--------------------+------+-------------+--------------------+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lets display\n",
    "df.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# extract columns to create time table\n",
    "# Udacity instructions:\n",
    "# time - timestamps of records in songplays broken down into specific units\n",
    "# start_time, hour, day, week, month, year, weekday\n",
    "# Example 1: https://sparkbyexamples.com/spark/spark-extract-hour-minute-and-second-from-timestamp/\n",
    "# Example 2: https://stackoverflow.com/questions/30949202/spark-dataframe-timestamptype-how-to-get-year-month-day-values-from-field\n",
    "time_table = df.withColumn(\"start_time\", F.col(\"start_time\")) \\\n",
    "               .withColumn(\"hour\", F.hour(F.col(\"start_time\"))) \\\n",
    "               .withColumn(\"day\", F.dayofmonth(F.col(\"start_time\"))) \\\n",
    "               .withColumn(\"week\", F.weekofyear(F.col(\"start_time\"))) \\\n",
    "               .withColumn(\"month\", F.month(F.col(\"start_time\"))) \\\n",
    "               .withColumn(\"year\", F.year(F.col(\"start_time\"))) \\\n",
    "               .withColumn(\"weekday\", F.dayofweek(F.col(\"start_time\"))) \\\n",
    "               .select(\"ts\",\"start_time\",\"hour\", \"day\", \"week\", \"month\", \"year\", \"weekday\").drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+----+---+----+-----+----+-------+\n",
      "|           ts|          start_time|hour|day|week|month|year|weekday|\n",
      "+-------------+--------------------+----+---+----+-----+----+-------+\n",
      "|1543595890796|2018-11-30 16:38:...|  16| 30|  48|   11|2018|      6|\n",
      "|1542605625796|2018-11-19 05:33:...|   5| 19|  47|   11|2018|      2|\n",
      "|1541267645796|2018-11-03 17:54:...|  17|  3|  44|   11|2018|      7|\n",
      "|1542986986796|2018-11-23 15:29:...|  15| 23|  47|   11|2018|      6|\n",
      "|1543349224796|2018-11-27 20:07:...|  20| 27|  48|   11|2018|      3|\n",
      "+-------------+--------------------+----+---+----+-----+----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lets display\n",
    "time_table.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# write time table to parquet files partitioned by year and month\n",
    "time_table.write.parquet(output_data + \"time/\", \n",
    "                         mode=\"overwrite\",\n",
    "                         partitionBy=[\"year\",\"month\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# read in song data to use for songplays table\n",
    "songs_parquet = output_data + 'songs/*/*/*.parquet'\n",
    "song_df = spark.read.parquet(songs_parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# extract columns from joined song and log datasets to create songplays table \n",
    "# Udacity instructions:\n",
    "# songplays - records in log data associated with song plays i.e. records with page NextSong\n",
    "# songplay_id, start_time, user_id, level, song_id, artist_id, session_id, location, user_agent\n",
    "# Example: https://dzone.com/articles/pyspark-join-explained-with-examples\n",
    "# Objects: [userId, location, gender, start_time, title, duration, sessionId, registration, song, lastName, itemInSession, artist, ts, page, userAgent, level, length, method, auth, firstName, song_id, status]\n",
    "songplays_table = df.join(song_df, [df.song == song_df.title], how='inner') \\\n",
    "                    .join(time_table, df.start_time == time_table.start_time, how=\"inner\") \\\n",
    "                    .select(F.monotonically_increasing_id().alias(\"songplay_id\"),\n",
    "                            df.start_time,\n",
    "                            df.userId.alias(\"user_id\"),\n",
    "                            df.level,\n",
    "                            song_df.song_id,\n",
    "                            df.artist.alias(\"artist_id\"), \n",
    "                            df.sessionId.alias(\"session_id\"), \n",
    "                            df.location, \n",
    "                            df.userAgent.alias(\"user_agent\"),\n",
    "                            time_table.year,\n",
    "                            time_table.month) \\\n",
    "                    .repartition(\"year\", \"month\") \\\n",
    "                    .drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+-------+-----+------------------+-----------------+----------+--------------------+--------------------+----+-----+\n",
      "|  songplay_id|          start_time|user_id|level|           song_id|        artist_id|session_id|            location|          user_agent|year|month|\n",
      "+-------------+--------------------+-------+-----+------------------+-----------------+----------+--------------------+--------------------+----+-----+\n",
      "| 188978561024|2018-11-21 21:56:...|     15| paid|SOZCTXZ12AB0182364|            Elena|       818|Chicago-Napervill...|\"Mozilla/5.0 (X11...|2018|   11|\n",
      "| 584115552256|2018-11-19 09:14:...|     24| paid|SOGDBUF12A8C140FAA|Calvin Richardson|       672|Lake Havasu City-...|\"Mozilla/5.0 (Win...|2018|   11|\n",
      "| 944892805120|2018-11-27 22:35:...|     80| paid|SOGDBUF12A8C140FAA|      Samy Deluxe|       992|Portland-South Po...|\"Mozilla/5.0 (Mac...|2018|   11|\n",
      "|1056561954816|2018-11-14 05:06:...|     10| free|SOGDBUF12A8C140FAA|        Percubaba|       484|Washington-Arling...|\"Mozilla/5.0 (Mac...|2018|   11|\n",
      "+-------------+--------------------+-------+-----+------------------+-----------------+----------+--------------------+--------------------+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lets display\n",
    "songplays_table.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# write songplays table to parquet files partitioned by year and month\n",
    "songplays_table.write.parquet(output_data + \"songplays/\", \n",
    "                              mode=\"overwrite\",\n",
    "                              partitionBy=[\"year\",\"month\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# End of all extractions and parquet savings. Lets have a look at the data we have produced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}